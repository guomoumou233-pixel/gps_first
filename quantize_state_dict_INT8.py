# quantize_linear_and_save_state_dict.py
# ç»“åˆäº† 'åªé‡åŒ– Linear' å’Œ 'åªä¿å­˜ state_dict' çš„æœ€ä½³å®è·µ

import os
import torch
import torch.nn as nn
from tiny_student_model import LightweightStudentCLIP # å‡è®¾è¿™ä¸ªæ–‡ä»¶åœ¨åŒç›®å½•ä¸‹

def quantize_and_save():
    # --- è·¯å¾„é…ç½® (ä»æ‚¨çš„è„šæœ¬ä¸­è·å–) ---
    fp32_path = "/root/mnist-clip/remoteclip_student_with_val2/BEST_student_model.pt"
    # ä½¿ç”¨æ–°çš„ä¿å­˜è·¯å¾„æ¥åŒºåˆ†æ–‡ä»¶
    save_path = "/root/mnist-clip/remoteclip_student_with_val2/quantized_LINEAR_ONLY_state_dict.pt"

    print("ğŸš€ æ­¥éª¤ 1: åŠ è½½ FP32 æ¨¡å‹...")
    model = LightweightStudentCLIP(vision_variant='L1', projection_dim=512)
    # ç¡®ä¿åŠ è½½çš„æ˜¯åŸå§‹ FP32 æ¨¡å‹çš„æƒé‡
    model.load_state_dict(torch.load(fp32_path, map_location="cpu"))
    model.eval()

    # --- å…³é”®ä¿®æ”¹ç‚¹ï¼šåªé‡åŒ– Linear å±‚ ---
    print("ğŸš€ æ­¥éª¤ 2: æ‰§è¡Œ Weight-Only INT8 åŠ¨æ€é‡åŒ– (ä»… Linear å±‚)...")
    
    # ä½¿ç”¨ qconfig_spec æ˜ç¡®æŒ‡å®šåªå¯¹ nn.Linear è¿›è¡ŒåŠ¨æ€é‡åŒ–
    quantized_model = torch.quantization.quantize_dynamic(
        model,
        qconfig_spec={
            # ä»…åŒ…å« Linear å±‚çš„é…ç½®
            nn.Linear: torch.ao.quantization.default_dynamic_qconfig,
        },
        dtype=torch.qint8
    )
    print("é‡åŒ–å®Œæˆï¼")

    # --- å…³é”®ä¿®æ”¹ç‚¹ï¼šåªä¿å­˜ state_dict ---
    print(f"ğŸš€ æ­¥éª¤ 3: ä»…ä¿å­˜é‡åŒ–åçš„æ¨¡å‹æƒé‡å­—å…¸ (state_dict) åˆ° {save_path}...")
    
    # ä»…ä¿å­˜ state_dict æ˜¯ PyTorch 2.6+ å…¼å®¹çš„æœ€å®‰å…¨æ–¹å¼
    torch.save(quantized_model.state_dict(), save_path)
    print("é‡åŒ–æƒé‡å·²ä¿å­˜ï¼")

    # --- å¤§å°å¯¹æ¯” ---
    if os.path.exists(fp32_path):
        orig = os.path.getsize(fp32_path) / 1024 / 1024
        q    = os.path.getsize(save_path) / 1024 / 1024
        print(f"\næ¨¡å‹å¤§å°å¯¹æ¯”:")
        print(f"åŸå§‹ FP32: {orig:.1f} MB")
        print(f"é‡åŒ– INT8: {q:.1f} MB (å‹ç¼© {orig/q:.2f}x)")
    else:
        print(f"\nè­¦å‘Š: æ‰¾ä¸åˆ°åŸå§‹æ¨¡å‹æ–‡ä»¶ {fp32_path}ï¼Œè·³è¿‡å¤§å°å¯¹æ¯”ã€‚")

if __name__ == "__main__":
    quantize_and_save()